{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"suF32iHpk1Gi"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import cv2\n","from keras.models import Model\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n","import os\n","import zipfile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u76QnIQxIoLW"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00pzGJjbE_yH"},"outputs":[],"source":["e = 42 #indicação do número da parte a retreinar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQkSZW7jk1Do"},"outputs":[],"source":["zip_ref = zipfile.ZipFile('/content/drive/My Drive/Full_dataset/' + str(e) + '.zip', 'r')\n","zip_ref.extractall(\"/tmp\")\n","zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O1m-iO7dX0gX"},"outputs":[],"source":["SIZE = 256\n","image_dataset = [] \n","mask_dataset = []  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3jhuVPeTZpqv"},"outputs":[],"source":["images = os.listdir('/tmp/' + str(e) + '/images/')\n","for i, image_name in enumerate(images):    \n","    if (image_name.split('.')[1] == 'tif'):\n","        print('Encontradas ' + str(len(image_dataset) + 1) + ' imagens')\n","        image = cv2.imread('/tmp/' + str(e) + '/images/' +image_name, cv2.IMREAD_UNCHANGED)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image_dataset.append(np.array(image))\n","\n","image_dataset = (tf.keras.utils.normalize(np.array(image_dataset), axis=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uvupNMihZhOR"},"outputs":[],"source":["masks = os.listdir('/tmp/' + str(e) + '/masks/')\n","for i, image_name in enumerate(masks):\n","    if (image_name.split('.')[1] == 'tif'):\n","        print('Encontradas ' + str(len(mask_dataset) + 1) + ' máscaras')\n","        image = cv2.imread('/tmp/' + str(e) + '/masks/' + image_name, 0)\n","        mask_dataset.append(np.array(image))\n","\n","mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nLl64qDtZlUr"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.2, random_state = 0)\n","\n","early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n","\n","filepath= '/content/drive/My Drive/Full_dataset/historico1/' + str(e) + '/weights-improvement-{epoch:02d}-{val_accuracy:.3f}.hdf5'\n","check = tf.keras.callbacks.ModelCheckpoint(filepath, monitor= 'val_accuracy', verbose=1, save_best_only=True, mode='max')\n","\n","csv = tf.keras.callbacks.CSVLogger('/content/drive/My Drive/Full_dataset/historico1/' + str(e) + '/mylogs.csv' , separator=';', append=False)\n","\n","callback = [early, check, csv]\n","\n","model = tf.keras.models.load_model('/content/drive/My Drive/Full_dataset/historico1/' + str(e-1) + '/weights-improvement-06-0.957.hdf5') #indicação do modelo a retreinar\n","\n","history = model.fit(X_train, y_train, \n","                    batch_size = 16, \n","                    callbacks = callback,\n","                    verbose=1, \n","                    epochs=1000, \n","                    validation_data=(X_test, y_test))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}