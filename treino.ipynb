{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"2gOI14ihVhGA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zGTHau3kNdII"},"outputs":[],"source":["import zipfile\n","\n","zip_ref = zipfile.ZipFile('/content/drive/My Drive/Full_dataset/1.zip', 'r')\n","zip_ref.extractall(\"/tmp\")\n","zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncDklen_Dvm8"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import cv2\n","from keras.models import Model\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n","import os\n","from keras import backend as K"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q6zDGmlaD8dt"},"outputs":[],"source":["def modelo_unet(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n","    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n","    s = inputs\n","\n","    #Contraction path\n","    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n","    c1 = Dropout(0.1)(c1)\n","    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","    \n","    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n","    c2 = Dropout(0.1)(c2)\n","    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","     \n","    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n","    c3 = Dropout(0.2)(c3)\n","    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","     \n","    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n","    c4 = Dropout(0.2)(c4)\n","    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n","    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n","     \n","    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n","    c5 = Dropout(0.3)(c5)\n","    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n","    \n","    #Expansive path \n","    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n","    u6 = concatenate([u6, c4])\n","    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n","    c6 = Dropout(0.2)(c6)\n","    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n","     \n","    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n","    u7 = concatenate([u7, c3])\n","    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n","    c7 = Dropout(0.2)(c7)\n","    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n","     \n","    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n","    u8 = concatenate([u8, c2])\n","    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n","    c8 = Dropout(0.1)(c8)\n","    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n","     \n","    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n","    u9 = concatenate([u9, c1], axis=3)\n","    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n","    c9 = Dropout(0.1)(c9)\n","    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n","     \n","    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n","     \n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    model.compile(optimizer='adam', loss=['binary_crossentropy'], metrics=['accuracy'])\n","    model.summary()\n","    \n","    return model\n"]},{"cell_type":"code","source":["SIZE = 256"],"metadata":{"id":"8TFCJnulx9ZN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m94v4rtLPoxt"},"outputs":[],"source":["image_dataset = [] \n","images = os.listdir('/tmp/1/images/')\n","for i, image_name in enumerate(images):    \n","    if (image_name.split('.')[1] == 'tif'):\n","        print('Encontradas ' + str(len(image_dataset) + 1) + ' imagens')\n","        image = cv2.imread('/tmp/1/images/' + image_name, cv2.IMREAD_UNCHANGED)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image_dataset.append(np.array(image))\n","\n","image_dataset = (tf.keras.utils.normalize(np.array(image_dataset), axis=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XsHtfq5Uo-VT"},"outputs":[],"source":["mask_dataset = []  \n","masks = os.listdir('/tmp/1/masks/')\n","for i, image_name in enumerate(masks):\n","    if (image_name.split('.')[1] == 'tif'):\n","        print('Encontradas ' + str(len(mask_dataset) + 1) + ' m√°scaras')\n","        image = cv2.imread('/tmp/1/masks/'+ image_name, 0)\n","        mask_dataset.append(np.array(image))\n","\n","mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVy2u2n0NQ0r"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.20, random_state = 0)\n","\n","IMG_HEIGHT = mask_dataset.shape[1]\n","IMG_WIDTH  = mask_dataset.shape[2]\n","IMG_CHANNELS = 3\n","\n","def get_model():\n","    return modelo_unet(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n","\n","model = get_model()\n","\n","early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n","\n","filepath='/content/drive/My Drive/Full_dataset/historico/1/weights-improvement-{epoch:02d}-{val_loss:.3f}.hdf5'\n","check = tf.keras.callbacks.ModelCheckpoint(filepath, monitor= 'val_accuracy', verbose=1, save_best_only=True, mode='max')\n","\n","csv = tf.keras.callbacks.CSVLogger('/content/drive/My Drive/Full_dataset/historico/1/mylogs.csv', separator=';' , append=False)\n","\n","callback = [early, check, csv]\n","\n","history = model.fit(X_train, y_train, \n","                    batch_size = 16, \n","                    callbacks = callback,\n","                    verbose=1, \n","                    epochs=1000, \n","                    validation_data=(X_test, y_test))\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}